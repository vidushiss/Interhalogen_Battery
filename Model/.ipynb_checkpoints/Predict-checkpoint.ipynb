{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd7bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# RDkit\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "IPythonConsole.ipython_useSVG = True # < use SVGs instead of PNGs\n",
    "IPythonConsole.drawOptions.addAtomIndices = True # adding indices\n",
    "IPythonConsole.molSize = 300, 300\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# logging\n",
    "import logging \n",
    "logging.basicConfig(format='%(message)s')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfe3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adjacency_matrix(adjacency_mat: np.ndarray, edges: list, map_indexes: dict = None):\n",
    "    \"\"\"\n",
    "    Function to make the adjacency matrix\n",
    "    :params adjacency_mat: numpy array - blank numpy array of n nodes sqaure\n",
    "    :params edges: iterable - iterable of paris of nodes to defined edges these \n",
    "                              will be sorted and indexed based on the sorted iterable\n",
    "    :return adjacency_mat: numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    log = logging.getLogger(__name__)\n",
    "    \n",
    "    if map_indexes is not None:\n",
    "        for ith, edg in enumerate(edges):\n",
    "            edges[ith] = (map_indexes[edg[0]], map_indexes[edg[1]])\n",
    "    \n",
    "    for i, j in edges:\n",
    "        log.debug(f\"updating {i}, {j}\")\n",
    "        adjacency_mat[i, j] = 1\n",
    "        \n",
    "    return adjacency_mat\n",
    "        \n",
    "def symmeterize_edges(edges: list):\n",
    "    \"\"\"\n",
    "    Function to make a symmetric set from an asymmetric set of edges\n",
    "    :param edges: list - list of edges\n",
    "    :return list - symmetric edges\n",
    "    \"\"\"\n",
    "    \n",
    "    log = logging.getLogger(__name__)\n",
    "    \n",
    "    new_edges = []\n",
    "    for e in edges:\n",
    "        log.debug(f\"updating {e[1]}, {e[0]}\")\n",
    "        new_edges.append((e[0], e[1]))\n",
    "        new_edges.append((e[1], e[0]))\n",
    "        \n",
    "    new_edges = sorted(list(set(new_edges)))\n",
    "    \n",
    "    return new_edges\n",
    "\n",
    "def adjacency_matrix(nodes: list, edges: list, symmetric: bool = None, self_connection: bool = False):\n",
    "    \"\"\"\n",
    "    Function to build an adjacency matrix from iterables of nodes and edges.\n",
    "    :param nodes: iterable - iterable of nodes these will be sorted \n",
    "                             and indexed based on the sorted iterable\n",
    "    :params edges: iterable - iterable of paris of nodes to defined edges these \n",
    "                              will be sorted and indexed based on the sorted iterable\n",
    "    :params symmetric: bool - (optional) None has no effect, True nodes have been input as \n",
    "                              directed without symmetric actions but the adjacency \n",
    "                              martix needs to be symmeterized, False use a \n",
    "                              unsymmetrerized adjacency\n",
    "    :params self_connection: bool - (optional) False nodes are not self connected unless explicitly given \n",
    "                                     True make all nodes self connected\n",
    "    :return matrix: np.array - adjacency matrix \n",
    "    \"\"\"\n",
    "    \n",
    "    log = logging.getLogger(__name__)\n",
    "    \n",
    "    n_nodes = len(nodes)\n",
    "    adjacency_mat = np.zeros((n_nodes, n_nodes))\n",
    "    \n",
    "    log.debug(adjacency_mat)\n",
    "    \n",
    "    node_idxs = {n: ith for ith, n in enumerate(sorted(nodes))}\n",
    "    \n",
    "    if symmetric is True:\n",
    "        edges = symmeterize_edges(edges)\n",
    "    edge_idxs = {e: ith for ith, e in enumerate(edges)}        \n",
    "    \n",
    "    adjacency_mat = make_adjacency_matrix(adjacency_mat, edges, map_indexes=node_idxs)\n",
    "    \n",
    "    if self_connection is True:\n",
    "        adjacency_mat = adjacency_mat + np.eye(n_nodes, n_nodes)\n",
    "    \n",
    "    log.info(adjacency_mat)\n",
    "    \n",
    "    return adjacency_mat\n",
    "    \n",
    "def electronegativity(element_label, return_dict=False, nan_swap=np.nan):\n",
    "    \"\"\"\n",
    "    Pauling electronegativity from Inorganic Chemistry Principles of Structure and Reactivity second Ed. James E. Huheey\n",
    "    pp162:164 Table 4.8 Electronegativities of the elements. Oxidation states are inculded for\n",
    "    some elements in (roman numerals) such as Fe(III)\n",
    "    :param element_label: str - element label as as string\n",
    "    :param return_dict: bool - return the electronegativity dictionary rather than a value\n",
    "    :param nan_sub: numeric - a numeric value to subsitute np.nan with. np.nan signifies the electronegativity \n",
    "                              is uknown or unmeasurable\n",
    "    :return: float or dictionary\n",
    "    >>> atomic_electronegativity(\"H\")\n",
    "    2.2\n",
    "    \"\"\"\n",
    "\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    electneg = {}\n",
    "    electneg[\"H\"] = 2.2\n",
    "    electneg[\"He\"] = np.nan\n",
    "    electneg[\"Li\"] = 0.98\n",
    "    electneg[\"Be\"] = 1.57\n",
    "    electneg[\"B\"] = 2.04\n",
    "    electneg[\"C\"] = 2.55\n",
    "    electneg[\"N\"] = 3.04\n",
    "    electneg[\"O\"] = 3.44\n",
    "    electneg[\"F\"] = 3.98\n",
    "    electneg[\"Ne\"] = np.nan\n",
    "    electneg[\"Na\"] = 0.93\n",
    "    electneg[\"Mg\"] = 1.31\n",
    "    electneg[\"Al\"] = 1.61\n",
    "    electneg[\"Si\"] = 1.9\n",
    "    electneg[\"P\"] = 2.19\n",
    "    electneg[\"S\"] = 2.58\n",
    "    electneg[\"Cl\"] = 3.16\n",
    "    electneg[\"Ar\"] = np.nan\n",
    "    electneg[\"K\"] = 0.82\n",
    "    electneg[\"Ca\"] = 1\n",
    "    electneg[\"Sc\"] = 1.36\n",
    "    electneg[\"Ti\"] = 1.54\n",
    "    electneg[\"Ti(II)\"] = 1.54\n",
    "    electneg[\"V\"] = 1.63\n",
    "    electneg[\"V(II)\"] = 1.563\n",
    "    electneg[\"Cr\"] = 1.66\n",
    "    electneg[\"Cr(II)\"] = 1.66\n",
    "    electneg[\"Mn\"] = 1.55\n",
    "    electneg[\"Mn(II)\"] = 1.55\n",
    "    electneg[\"Fe\"] = 1.83\n",
    "    electneg[\"Fe(II)\"] = 1.83\n",
    "    electneg[\"Fe(III)\"] = 1.96\n",
    "    electneg[\"Co\"] = 1.88\n",
    "    electneg[\"Co(II)\"] = 1.88\n",
    "    electneg[\"Ni\"] = 1.91\n",
    "    electneg[\"Ni(II)\"] = 1.91\n",
    "    electneg[\"Cu\"] = 1.9\n",
    "    electneg[\"Cu(I)\"] = 1.9\n",
    "    electneg[\"Cu(II)\"] = 2\n",
    "    electneg[\"Zn\"] = 1.65\n",
    "    electneg[\"Zn(II)\"] = 1.65\n",
    "    electneg[\"Ga\"] = 1.81\n",
    "    electneg[\"Ga(III)\"] = 1.81\n",
    "    electneg[\"Ge\"] = 2.01\n",
    "    electneg[\"Ge(IV)\"] = 2.01\n",
    "    electneg[\"As\"] = 2.18\n",
    "    electneg[\"As(III)\"] = 2.18\n",
    "    electneg[\"Se\"] = 2.55\n",
    "    electneg[\"Br\"] = 2.96\n",
    "    electneg[\"Kr\"] = 2.9\n",
    "    electneg[\"Rb\"] = 0.82\n",
    "    electneg[\"Sr\"] = 0.95\n",
    "    electneg[\"Y\"] = 1.22\n",
    "    electneg[\"Zr\"] = 1.33\n",
    "    electneg[\"Zr(II)\"] = 1.33\n",
    "    electneg[\"Nb\"] = 1.6\n",
    "    electneg[\"Mo\"] = 2.16\n",
    "    electneg[\"Mo(II)\"] = 2.16\n",
    "    electneg[\"Mo(III)\"] = 2.19\n",
    "    electneg[\"Mo(IV)\"] = 2.24\n",
    "    electneg[\"Mo(V)\"] = 2.27\n",
    "    electneg[\"Mo(VI)\"] = 2.35\n",
    "    electneg[\"Tc\"] = 1.9\n",
    "    electneg[\"Ru\"] = 2.2\n",
    "    electneg[\"Rh\"] = 2.28\n",
    "    electneg[\"Pd\"] = 2.2\n",
    "    electneg[\"Ag\"] = 1.93\n",
    "    electneg[\"Cd\"] = 1.69\n",
    "    electneg[\"In\"] = 1.78\n",
    "    electneg[\"Sn\"] = 1.96\n",
    "    electneg[\"Sn(II)\"] = 1.8\n",
    "    electneg[\"Sn(IV)\"] = 1.96\n",
    "    electneg[\"Sb\"] = 2.05\n",
    "    electneg[\"Te\"] = 2.1\n",
    "    electneg[\"I\"] = 2.66\n",
    "    electneg[\"Xe\"] = 2.6\n",
    "    electneg[\"Cs\"] = 0.79\n",
    "    electneg[\"Ba\"] = 0.89\n",
    "    electneg[\"La\"] = 1.1\n",
    "    electneg[\"Ce\"] = 1.12\n",
    "    electneg[\"Pr\"] = 1.13\n",
    "    electneg[\"Nd\"] = 1.14\n",
    "    electneg[\"Pm\"] = np.nan\n",
    "    electneg[\"Sm\"] = 1.17\n",
    "    electneg[\"Eu\"] = np.nan\n",
    "    electneg[\"Gd\"] = 1.2\n",
    "    electneg[\"Tb\"] = np.nan\n",
    "    electneg[\"Dy\"] = 1.22\n",
    "    electneg[\"Ho\"] = 1.23\n",
    "    electneg[\"Er\"] = 1.24\n",
    "    electneg[\"Tm\"] = 1.25\n",
    "    electneg[\"Yb\"] = np.nan\n",
    "    electneg[\"Lu\"] = 1.27\n",
    "    electneg[\"Hf\"] = 1.3\n",
    "    electneg[\"Ta\"] = 1.5\n",
    "    electneg[\"W\"] = 2.36\n",
    "    electneg[\"Re\"] = 1.9\n",
    "    electneg[\"Os\"] = 2.2\n",
    "    electneg[\"Ir\"] = 2.2\n",
    "    electneg[\"Pt\"] = 2.28\n",
    "    electneg[\"Au\"] = 2.54\n",
    "    electneg[\"Hg\"] = 2\n",
    "    electneg[\"Tl\"] = 1.62\n",
    "    electneg[\"Tl(I)\"] = 1.62\n",
    "    electneg[\"Tl(III)\"] = 2.04\n",
    "    electneg[\"Pb\"] = 2.33\n",
    "    electneg[\"Pb(II)\"] = 1.87\n",
    "    electneg[\"Pb(IV)\"] = 2.33\n",
    "    electneg[\"Bi\"] = 2.02\n",
    "    electneg[\"Po\"] = 2\n",
    "    electneg[\"At\"] = 2.2\n",
    "    electneg[\"Rn\"] = np.nan\n",
    "    electneg[\"Fr\"] = 0.7\n",
    "    electneg[\"Ra\"] = 0.9\n",
    "    electneg[\"Ac\"] = 1.1\n",
    "    electneg[\"Th\"] = 1.3\n",
    "    electneg[\"Pa\"] = 1.5\n",
    "    electneg[\"U\"] = 1.7\n",
    "    electneg[\"Np\"] = 1.3\n",
    "    electneg[\"Pu\"] = 1.3\n",
    "    electneg[\"Am\"] = 1.3\n",
    "    electneg[\"Cm\"] = 1.3\n",
    "    electneg[\"Bk\"] = 1.3\n",
    "    electneg[\"Cf\"] = 1.3\n",
    "    electneg[\"Es\"] = 1.3\n",
    "    electneg[\"Fm\"] = 1.3\n",
    "    electneg[\"Md\"] = 1.3\n",
    "    electneg[\"No\"] = 1.3\n",
    "    electneg[\"Lr\"] = np.nan\n",
    "    electneg[\"Rf\"] = np.nan\n",
    "    electneg[\"Db\"] = np.nan\n",
    "    electneg[\"Sg\"] = np.nan\n",
    "    electneg[\"Bh\"] = np.nan\n",
    "    electneg[\"Hs\"] = np.nan\n",
    "    electneg[\"Mt\"] = np.nan\n",
    "    electneg[\"Ds\"] = np.nan\n",
    "    electneg[\"Rg\"] = np.nan\n",
    "    electneg[\"Cn\"] = np.nan\n",
    "    electneg[\"Nh\"] = np.nan\n",
    "    electneg[\"Fl\"] = np.nan\n",
    "    electneg[\"Mc\"] = np.nan\n",
    "    electneg[\"Lv\"] = np.nan\n",
    "    electneg[\"Ts\"] = np.nan\n",
    "    electneg[\"Og\"] = np.nan\n",
    "\n",
    "    electneg = {k.lower(): v for k, v in electneg.items()}\n",
    "\n",
    "    if not np.isnan(nan_swap):\n",
    "        electneg = {(k if not np.isnan(v) else k) : (v if not np.isnan(v) else nan_swap) for k, v in electneg.items()}\n",
    "\n",
    "    if return_dict is True:\n",
    "        return electneg\n",
    "    elif element_label.lower() in electneg.keys():\n",
    "        return electneg[element_label.lower()]\n",
    "    else:\n",
    "        log.error(\"Error no electronegativity for element label {}\".format(element_label))\n",
    "        raise RuntimeError\n",
    "\n",
    "def get_atomic_number(atom):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return atom.GetAtomicNum()\n",
    "\n",
    "def get_electronegativity(atom):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return electronegativity(atom.GetSymbol())\n",
    "\n",
    "def bond_type_encoder(bondtype: str = None, return_dict: bool = False):\n",
    "    \"\"\"\n",
    "    Return a unique integer encoding for all bond types RDKit can recognize\n",
    "    :param bondtype: str - string defining the bond type from RDkit (bond.GetBondType())\n",
    "    :return int\n",
    "    \"\"\"\n",
    "    encoder = {}\n",
    "    encoder[None] = 0\n",
    "    encoder[\"SINGLE\"] = 1\n",
    "    encoder[\"DOUBLE\"] = 2\n",
    "    encoder[\"TRIPLE\"] = 3\n",
    "    encoder[\"QUADRUPLE\"] = 4\n",
    "    encoder[\"QUINTUPLE\"] = 5\n",
    "    encoder[\"HEXTUPLE\"] = 6\n",
    "    encoder[\"ONEANDAHALF\"] = 7\n",
    "    encoder[\"TWOANDAHALF\"] = 8\n",
    "    encoder[\"THREEANDAHALF\"] = 9\n",
    "    encoder[\"FOURANDAHALF\"] = 10\n",
    "    encoder[\"FIVEANDAHALF\"] = 11\n",
    "    encoder[\"AROMATIC\"] = 12\n",
    "    encoder[\"IONIC\"] = 13\n",
    "    encoder[\"HYDROGEN\"] = 14\n",
    "    encoder[\"THREECENTER\"] = 15\n",
    "    encoder[\"DATIVEONE\"] = 16\n",
    "    encoder[\"DATIVE\"] = 17\n",
    "    encoder[\"DATIVEL\"] = 18\n",
    "    encoder[\"DATIVER\"] = 19\n",
    "    encoder[\"OTHER\"] = 20\n",
    "    encoder[\"ZERO\"] = 21\n",
    "    encoder[\"UNSPECIFIED\"] = 22\n",
    "    \n",
    "            \n",
    "    if return_dict is False:\n",
    "        return encoder[bondtype.upper()]\n",
    "    elif return_dict is True:\n",
    "        return encoder\n",
    "\n",
    "def get_bond_type(bond):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    return bond_type_encoder(str(bond.GetBondType()))\n",
    "\n",
    "\n",
    "class NodeFeatures(object):\n",
    "    \"\"\"\n",
    "    Class to store and generate node features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, add_feature_functions: list = [get_atomic_number], use_default_feature: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the class here\n",
    "        \"\"\"\n",
    "        \n",
    "        self.feature_functions = add_feature_functions\n",
    "        \n",
    "    def add_feature_function(self, feature_function):\n",
    "        \"\"\"\n",
    "        Function to add a feature function to the class \n",
    "        the feature function should take only an RDKit \n",
    "        atom as its arguments\n",
    "        \"\"\"\n",
    "        \n",
    "        self.feature_functions.append(feature_function)\n",
    "        self.feature_functions = self.feature_functions\n",
    "        \n",
    "    def get_feture_functions(self):\n",
    "        \"\"\"\n",
    "        Function to return the current set of feature functions\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.feature_functions\n",
    "        \n",
    "    def calculate_features(self, atom):\n",
    "        \"\"\"\n",
    "        Function to calculate the features\n",
    "        \"\"\"\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for feat in self.feature_functions:\n",
    "            output.append(feat(atom))\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def get_feature_tensor(self, mol: rdkit.Chem.rdchem.Mol):\n",
    "        \"\"\"\n",
    "        Function to take a molecules are return the node part of the graph as a tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_order = [str(f).split()[1] for f in self.get_feture_functions()]\n",
    "        node_tensor = np.zeros((mol.GetNumAtoms(), len(self.feature_functions)))\n",
    "        \n",
    "        for atom in mol.GetAtoms():\n",
    "            v = self.calculate_features(atom)\n",
    "            for ith in range(len(self.feature_functions)):\n",
    "                node_tensor[atom.GetIdx()][ith] = v[ith]\n",
    "        \n",
    "        return node_tensor, feature_order\n",
    "        \n",
    "        \n",
    "class EdgeFeatures(object):\n",
    "    \"\"\"\n",
    "    Class to store and generate edge features\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, add_feature_functions: list = [get_bond_type], use_default_feature: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize the class here\n",
    "        \"\"\"\n",
    "        \n",
    "        self.feature_functions = add_feature_functions\n",
    "        \n",
    "    def add_feature_function(self, feature_function):\n",
    "        \"\"\"\n",
    "        Function to add a feature function to the class \n",
    "        the feature function should take only an RDKit \n",
    "        atom as its arguments\n",
    "        \"\"\"\n",
    "        \n",
    "        self.feature_functions.append(feature_function)\n",
    "        self.feature_functions = self.feature_functions\n",
    "        \n",
    "    def get_feture_functions(self):\n",
    "        \"\"\"\n",
    "        Function to return the current set of feature functions\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.feature_functions\n",
    "        \n",
    "    def calculate_features(self, bond):\n",
    "        \"\"\"\n",
    "        Function to calculate the features\n",
    "        \"\"\"\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for feat in self.feature_functions:\n",
    "            output.append(feat(bond))\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def get_adjacency_matrix(self, mol: rdkit.Chem.rdchem.Mol, use_bond_order=False, self_connection=False):\n",
    "        \"\"\"\n",
    "        Function to get a molecule adjacency matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        mat = GetAdjacencyMatrix(mol, useBO=use_bond_order)\n",
    "        \n",
    "        if self_connection is True:\n",
    "            mat = mat + np.eye(mol.GetNumAtoms(), mol.GetNumAtoms())\n",
    "            \n",
    "        return mat\n",
    "        \n",
    "    \n",
    "    def get_feature_tensor(self, mol: rdkit.Chem.rdchem.Mol, symmetric=True, verbose=False):\n",
    "        \"\"\"\n",
    "        Function to take a molecule then return the edge part of the graph as a tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        feature_order = [str(f).split()[1] for f in self.get_feture_functions()]\n",
    "        edge_tensor = np.zeros((mol.GetNumAtoms(), mol.GetNumAtoms(), len(self.feature_functions)))\n",
    "        \n",
    "        if symmetric is True:\n",
    "            for bond in mol.GetBonds():\n",
    "                x = min(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "                y = max(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "                v = self.calculate_features(bond)\n",
    "                for ith in range(len(self.feature_functions)):\n",
    "                    edge_tensor[x, y, ith] = v[ith]\n",
    "                    edge_tensor[y, x, ith] = v[ith]\n",
    "                    if verbose is True:\n",
    "                        log.info(\"edge_tensor[{0}, {1}, {2}] = {3}\\n\"\n",
    "                              \"edge_tensor[{1}, {0}, {2}] = {3}\".format(x, y ,ith, v[ith]))\n",
    "        elif symmetric is False:\n",
    "            for bond in mol.GetBonds():\n",
    "                x = min(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "                y = max(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx())\n",
    "                v = self.calculate_features(bond)\n",
    "                for ith in range(len(self.feature_functions)):\n",
    "                    edge_tensor[x, y, ith] = v[ith]\n",
    "                    if verbose is True:\n",
    "                        log.info(\"edge_tensor[{0}, {1}, {2}] = {3}\\n\"\n",
    "                        \"edge_tensor[{1}, {0}, {2}] = {4}\".format(x, y ,ith, v[ith], edge_tensor[y, x, ith]))\n",
    "        else:\n",
    "            log.warning(\"WARNING - symmetric must be set to 1 or 0\")\n",
    "            return None, None\n",
    "        \n",
    "        return edge_tensor, feature_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b013ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training network for 8 formulants over 8 examples\n"
     ]
    }
   ],
   "source": [
    "formulation_file = \"dummy_loading47sep2_bob0test.csv\"\n",
    "data = pd.read_csv(formulation_file)\n",
    "data.columns = [ent.strip() for ent in data.columns]\n",
    "\n",
    "property_columns = [\"cap\"]\n",
    "max_atomic_number_to_represent = 118\n",
    "n_node_features = 100\n",
    "n_node_features = int(n_node_features)\n",
    "\n",
    "formulations_smiles_columns = [\"smiles1\", \"smiles2\", \"smiles3\", \"smiles4\", \"smiles5\", \"smiles6\", \"smiles7\", \"smiles8\"]\n",
    "assert all(ent in data.columns for ent in formulations_smiles_columns), \"ERROR - formulation smiles column header not found in data\"\n",
    "\n",
    "formulations_concer_columns = [\"conc1\", \"conc2\", \"conc3\", \"conc4\", \"conc5\", \"conc6\", \"conc7\", \"conc8\"]\n",
    "assert all(ent in data.columns for ent in formulations_concer_columns), \"ERROR - formulation concerntration column header not found in data\"\n",
    "\n",
    "cathode_loading_columns = [\"Cath loading\", \"sep\"]\n",
    "\n",
    "n_formaulatants = len(formulations_smiles_columns)\n",
    "n_conc = len(formulations_concer_columns)\n",
    "assert n_formaulatants == n_conc, \"ERROR - the number of molecules in the formulation and the number of concerntration do not match\"\n",
    "\n",
    "formulation_indx = [ith for ith in range(len(data.index))]\n",
    "\n",
    "log.info(\"Training network for {} formulants over {} examples\".format(n_formaulatants, len(formulation_indx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62fd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bond_type_encoder(bondtype: str = None, return_dict: bool = False):\n",
    "    \"\"\"\n",
    "    Return a unique integer encoding for all bond types RDKit can recognize\n",
    "    :param bondtype: str - string defining the bond type from RDkit (bond.GetBondType())\n",
    "    :return int\n",
    "    \"\"\"\n",
    "    encoder = {}\n",
    "    encoder[None] = 0\n",
    "    encoder[\"SINGLE\"] = 1\n",
    "    encoder[\"DOUBLE\"] = 2\n",
    "    encoder[\"TRIPLE\"] = 3\n",
    "    encoder[\"QUADRUPLE\"] = 4\n",
    "    encoder[\"QUINTUPLE\"] = 5\n",
    "    encoder[\"HEXTUPLE\"] = 6\n",
    "    encoder[\"ONEANDAHALF\"] = 7\n",
    "    encoder[\"TWOANDAHALF\"] = 8\n",
    "    encoder[\"THREEANDAHALF\"] = 9\n",
    "    encoder[\"FOURANDAHALF\"] = 10\n",
    "    encoder[\"FIVEANDAHALF\"] = 11\n",
    "    encoder[\"AROMATIC\"] = 12\n",
    "    encoder[\"IONIC\"] = 13\n",
    "    encoder[\"HYDROGEN\"] = 14\n",
    "    encoder[\"THREECENTER\"] = 15\n",
    "    encoder[\"DATIVEONE\"] = 16\n",
    "    encoder[\"DATIVE\"] = 17\n",
    "    encoder[\"DATIVEL\"] = 18\n",
    "    encoder[\"DATIVER\"] = 19\n",
    "    encoder[\"OTHER\"] = 20\n",
    "    encoder[\"ZERO\"] = 21\n",
    "    encoder[\"UNSPECIFIED\"] = 22\n",
    "    \n",
    "            \n",
    "    if return_dict is False:\n",
    "        return encoder[bondtype.upper()]\n",
    "    elif return_dict is True:\n",
    "        return encoder\n",
    "\n",
    "def get_adjacency_matrix(mol: rdkit.Chem.rdchem.Mol, use_bond_order=False, self_connection=False):\n",
    "    \"\"\"\n",
    "    Function to get a molecule adjacency matrix\n",
    "    \"\"\"\n",
    "\n",
    "    mat = GetAdjacencyMatrix(mol, useBO=use_bond_order)\n",
    "\n",
    "    if self_connection is True:\n",
    "        mat = mat + np.eye(mol.GetNumAtoms(), mol.GetNumAtoms())\n",
    "\n",
    "    return mat\n",
    "    \n",
    "def smiles_to_graph_input(data, smiles_cols, conc_cols, prop_cols, n_formaulatants, loading, n_node_features= 100, max_atomic_number_to_represent=118):\n",
    "    \"\"\"\n",
    "    Function to output N graphs and N properties for a given input formulation.\n",
    "    The formulation data should be in a csv file (or equivalent) read by pandas.\n",
    "    The read in data is given to the data variable. The column headers for the smiles, concerntrations\n",
    "    and properties are given reprectively to smiles_cols, conc_cols, prop_cols as lists. The number\n",
    "    of molecules in a formaulation needs to be consistent (for now) n_formaulatants is a integer tah tdefine this\n",
    "    :param data: pandas.Series - a row from a read file as a dataframe of formulations to run over\n",
    "    :param smiles_cols: list - list of columns which contain the smiles strings for each component of the formulation\n",
    "    :param conc_cols: list - list of columns which contain the concerntration floats for each component of the formulation\n",
    "    :param prop_cols: list - list of columns which contain the properties to predict for each formulation\n",
    "    :param n_formaulatants: int - number of molecule components in each formulation needs to be the same for all\n",
    "    :param max_atomic_number_to_represent: int - the highest atomic number to encode for a node\n",
    "    :return tuple nodesX (0 -> n_formaulatants), adjacency matrixX (0 -> n_formaulatants), concerntrations\n",
    "    \"\"\"\n",
    "    # Get the concerntrations from the series and set them to be a numpy array \n",
    "    wt = data[conc_cols].astype(float).to_numpy()\n",
    "    cath = data[loading].astype(float).to_numpy()\n",
    "    wt = wt/100\n",
    "    # Get the smiles as a numpy array\n",
    "    smiles = np.array([ent.strip() for ent in data[smiles_cols].astype(str)])\n",
    "    \n",
    "    graphs = [] # Note the order is important nodes0, adjacency matrix0, nodes1, adjacencey matrix1 .....\n",
    "    \n",
    "    # Dictionary to encode all RDKit bond types\n",
    "    bond_encoder = bond_type_encoder(return_dict=True)\n",
    "    \n",
    "    # Make the graphs\n",
    "    for ith, smile in enumerate(smiles):\n",
    "        mol = Chem.MolFromSmiles(smile, sanitize=False)\n",
    "        mol.UpdatePropertyCache(strict=False)\n",
    "        mol = Chem.AddHs(mol)\n",
    "         \n",
    "    \n",
    "        \n",
    "        n_atoms = mol.GetNumAtoms()\n",
    "        \n",
    "        # Assume max elements to consider is 118 make a blank numpy array to encode which element are present in the molecule\n",
    "        node = np.zeros((n_atoms, n_node_features))\n",
    "        for atom in mol.GetAtoms():\n",
    "            node[atom.GetIdx(), atom.GetAtomicNum()-1] = electronegativity(atom.GetSymbol(), nan_swap=0.0)\n",
    "            \n",
    "        graphs.append(node)\n",
    "        \n",
    "        # Get the adjacency matrix\n",
    "        adjacency_matrix = get_adjacency_matrix(mol, use_bond_order=True, self_connection=True)\n",
    "        \n",
    "        graphs.append(adjacency_matrix)\n",
    "        \n",
    "    \n",
    "    node0, adj0, node1, adj1, node2, adj2, node3, adj3, node4, adj4, node5, adj5, node6, adj6, node7, adj7 = graphs\n",
    "    return node0, adj0, node1, adj1, node2, adj2, node3, adj3, node4, adj4, node5, adj5,node6, adj6, node7, adj7, wt, cath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea224e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"Implementation of GCN as layer\"\"\"\n",
    "\n",
    "    def __init__(self, activation=None, **kwargs):\n",
    "        # constructor, which just calls super constructor\n",
    "        # and turns requested activation into a callable function\n",
    "        super(GCNLayer, self).__init__(**kwargs)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # create trainable weights\n",
    "        node_shape, adj_shape = input_shape\n",
    "        self.w = self.add_weight(shape=(node_shape[2], node_shape[2]), name=\"w\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # split input into nodes, adj\n",
    "        nodes, adj = inputs\n",
    "        # compute degree\n",
    "        \n",
    "        degree = tf.reduce_sum(adj, axis=-1)\n",
    "        # GCN equation\n",
    "        # degree[b,i] * adj[b, i, j] * nodes[b, j, k] * weights[k, l]\n",
    "        new_nodes = tf.einsum(\"bi,bij,bjk,kl->bil\", 1 / degree, adj, nodes, self.w)\n",
    "        out = self.activation(new_nodes)\n",
    "        return out, adj\n",
    "\n",
    "class GRLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"A GNN layer that computes average over all node features\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"GRLayer\", **kwargs):\n",
    "        super(GRLayer, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        nodes, adj = inputs\n",
    "        reduction = tf.reduce_mean(nodes, axis=1)\n",
    "        return reduction\n",
    "    \n",
    "def gcn_mols(n_node_features):\n",
    "    \n",
    "    ninput = tf.keras.Input((None,n_node_features,))\n",
    "    ainput = tf.keras.Input((None,None,))\n",
    "    \n",
    "    \n",
    "    layer1 = GCNLayer(\"tanh\")([ninput, ainput])\n",
    "    layer2 = GCNLayer(\"tanh\")(layer1)\n",
    "    layer3 = GCNLayer(\"tanh\")(layer2)\n",
    "    layer4 = GCNLayer(\"tanh\")(layer3)\n",
    "    # reduce to graph features\n",
    "    layer5 = GRLayer()(layer4)\n",
    "    # standard layers (the readout)\n",
    "     #output = tf.keras.layers.Dense(10)(layer5)\n",
    "    output = tf.keras.layers.Dense(1)(layer5)\n",
    "    \n",
    "    return keras.Model(inputs=(ninput, ainput), outputs=layer5)\n",
    "\n",
    "def gen_graphs_and_labels(data, formulations_smiles_columns, formulations_concer_columns, property_columns, n_formaulatants, cathode_loading_columns):\n",
    "    cols = formulations_smiles_columns + formulations_concer_columns + property_columns + cathode_loading_columns\n",
    "    for i in data.index:\n",
    "        graphs = smiles_to_graph_input(data.loc[i, cols], formulations_smiles_columns, formulations_concer_columns, property_columns, n_formaulatants, cathode_loading_columns)\n",
    "        label = data.loc[i, property_columns].astype(float).to_numpy()\n",
    "        yield graphs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ddfb389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Output shapes\n",
      "[TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(8,), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None)]\n"
     ]
    }
   ],
   "source": [
    "output_signature_list = []\n",
    "\n",
    "for i in range(n_formaulatants):\n",
    "    output_signature_list.append(tf.TensorSpec(shape=(None, n_node_features),  dtype=tf.float32))\n",
    "    output_signature_list.append(tf.TensorSpec(shape=(None, None),  dtype=tf.float32))\n",
    "    \n",
    "output_signature_list = output_signature_list +[tf.TensorSpec(shape=(n_formaulatants,), dtype=tf.float32)]+ [tf.TensorSpec(shape=(2,), dtype=tf.float32)] \n",
    "\n",
    "log.info(\"\\nOutput shapes\\n{}\".format(output_signature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05423f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data set <_FlatMapDataset element_spec=((TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(8,), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.float32, name=None)), TensorSpec(shape=(1,), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: gen_graphs_and_labels(data, formulations_smiles_columns, formulations_concer_columns, property_columns, n_formaulatants, cathode_loading_columns),\n",
    "    output_signature=(tuple(output_signature_list), (tf.TensorSpec(shape=(1,),  dtype=tf.float32))\n",
    "                 ),\n",
    ")\n",
    "                      \n",
    "\n",
    "\n",
    "log.info(f\"data set {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af748a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N node features 100\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpointhlem/my_checkpoint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     formulation_inputs[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madj\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput((\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,),)\n\u001b[1;32m      9\u001b[0m     model_molecule[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelmolecule\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gcn_mols(n_node_features)\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mmodel_molecule\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodelmolecule\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./checkpointhlem/my_checkpoint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     model_molecule[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelmolecule\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m wt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput((\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m),)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py:31\u001b[0m, in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     27\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot found in checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to find any \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching files for\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[0;32m---> 31\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSliced checkpoints are not supported\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_message \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupported\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m error_message:\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors_impl\u001b[38;5;241m.\u001b[39mUnimplementedError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, error_message)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./checkpointhlem/my_checkpoint"
     ]
    }
   ],
   "source": [
    "formulation_inputs = {}\n",
    "model_molecule = {}\n",
    "log.info(f\"N node features {n_node_features}\")\n",
    "for i in range(n_formaulatants):\n",
    "    formulation_inputs[f\"node{i}\"] = tf.keras.Input((None, n_node_features,),)\n",
    "    \n",
    "    formulation_inputs[f\"adj{i}\"]= tf.keras.Input((None, None,),)\n",
    "    \n",
    "    model_molecule[f\"modelmolecule{i}\"] = gcn_mols(n_node_features)\n",
    "    model_molecule[f\"modelmolecule{i}\"].load_weights('./checkpointhlem/my_checkpoint')\n",
    "    model_molecule[f\"modelmolecule{i}\"].trainable = False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "wt = tf.keras.Input((None, None),)\n",
    "cath = tf.keras.Input((2,),)\n",
    "\n",
    "log.debug(f\"\\nformultion inps\\n{formulation_inputs}\\n\")\n",
    "\n",
    "log.debug(f\"wt\\n{wt}\")\n",
    "log.debug(f\"wt\\n{cath}\")\n",
    "gcn_out = {}\n",
    "gcn_wt = {}\n",
    "for i in range(n_formaulatants):\n",
    "    #globals()['gcn_out%s'%i] = globals()['modelmolecule%s'%i]([globals()['node%s'%i], globals()['adj%s'%i]])\n",
    "    #globals()['gcn_wt%s'%i] = layers.Multiply()([globals()['gcn_out%s'%i], wt[:,i]])\n",
    "    \n",
    "    gcn_out[f\"gcn_out{i}\"] = model_molecule[f'modelmolecule{i}']([formulation_inputs[f'node{i}'], formulation_inputs[f'adj{i}']])\n",
    "    gcn_wt[f'gcn_wt{i}'] = layers.Multiply()([gcn_out[f'gcn_out{i}'], wt[:,i]])\n",
    "    \n",
    "    log.debug(f\"\\n{i} [gcn_out[f'gcn_out{i}'], wt[:,i]] = {[gcn_out[f'gcn_out{i}'], wt[:,i]]}\\n\")\n",
    "\n",
    "log.debug(f\"\\ngcn out {gcn_out[f'gcn_out0']}\\n\")\n",
    "log.debug(f\"\\ngcn wt {gcn_wt[f'gcn_wt0']}\\n\")\n",
    "    \n",
    "log.debug(\"\\nLayers to add\\n{}\\n\".format([v for _, v in gcn_wt.items()]))\n",
    "x1 = layers.concatenate([v for _, v in gcn_wt.items()])\n",
    "#x = layers.Dense(10, activation='relu')(x)\n",
    "\n",
    "#x2 = layers.Dense(1000, activation='relu')(x1)\n",
    "x3 = layers.concatenate([x1, cath])\n",
    "#x = layers.Dense(500, activation='relu')(x)\n",
    "x = layers.Dense(1000, activation='relu')(x3)\n",
    "x = layers.Dense(500, activation='relu')(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "performance = layers.Dense(1)(x)\n",
    "\n",
    "inps = []\n",
    "for ith in range(n_formaulatants):\n",
    "    inps.append(formulation_inputs[f\"node{ith}\"])\n",
    "    inps.append(formulation_inputs[f\"adj{ith}\"])\n",
    "\n",
    "inps = inps +[wt] +[cath]\n",
    "#tuple(inps)\n",
    "\n",
    "log.debug(f\"inps\\n{inps}\\n\")\n",
    "\n",
    "log.info(f\"inputs {inps}\\n\")\n",
    "\n",
    "electrolyte_model = keras.Model(inputs=inps, outputs=performance)\n",
    "#electrolyte_model = keras.Model(inputs=[node0,adj0,node1,adj1,node2,adj2,node3,adj3,wt], outputs=capacity)\n",
    "\n",
    "electrolyte_model.summary()\n",
    "#keras.utils.plot_model(electrolyte_model, \"my_formulation_model1.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c405fcb-50c4-42f5-9321-899bd63fa908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 162ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 16:47:49.641056: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "electrolyte_model= tf.keras.models.load_model(\"TL_model_cat5\")\n",
    "prediction = electrolyte_model.predict(dataset.batch(1))\n",
    "\n",
    "np.savetxt('dummy_loading47sep2_bob0test.txt', prediction, fmt='%.18e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrolyte_model.compile(optimizer= opt, loss=tf.keras.losses.MeanSquaredError())\n",
    "result = electrolyte_model.fit(\n",
    "    dataset.batch(1), epochs=8000, shuffle=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "electrolyte_model.save(\"TL_model_cat4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8760442c-2055-46a5-af25-812931137329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: TL_model1_8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assets written to: TL_model1_8/assets\n"
     ]
    }
   ],
   "source": [
    "electrolyte_model.save(\"TL_model1_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bf5deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 17:10:09.036409: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 14ms/step - loss: 1674.2679\n",
      "Epoch 2/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1668.6570\n",
      "Epoch 3/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1668.5942\n",
      "Epoch 4/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1667.7924\n",
      "Epoch 5/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1668.0760\n",
      "Epoch 6/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1667.5325\n",
      "Epoch 7/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1667.8574\n",
      "Epoch 8/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1668.3540\n",
      "Epoch 9/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1667.1677\n",
      "Epoch 10/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1666.8876\n",
      "Epoch 11/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1667.1786\n",
      "Epoch 12/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1666.1295\n",
      "Epoch 13/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1666.1007\n",
      "Epoch 14/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1666.9294\n",
      "Epoch 15/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1665.2330\n",
      "Epoch 16/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1665.3702\n",
      "Epoch 17/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1665.7358\n",
      "Epoch 18/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1665.8333\n",
      "Epoch 19/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1664.7585\n",
      "Epoch 20/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1665.3704\n",
      "Epoch 21/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1665.1292\n",
      "Epoch 22/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1665.8606\n",
      "Epoch 23/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1663.9923\n",
      "Epoch 24/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1663.2858\n",
      "Epoch 25/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1664.7650\n",
      "Epoch 26/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1663.9512\n",
      "Epoch 27/4000\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 1663.1284\n",
      "Epoch 28/4000\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1664.2006\n",
      "Epoch 29/4000\n",
      "56/72 [======================>.......] - ETA: 0s - loss: 1384.3632"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m opt\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00001\u001b[39m)\n\u001b[1;32m      9\u001b[0m electrolyte_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m opt, loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43melectrolyte_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m electrolyte_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTL_model1_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt= tf.keras.optimizers.legacy.Adam(learning_rate=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "electrolyte_model.compile(optimizer= opt, loss=tf.keras.losses.MeanSquaredError())\n",
    "result = electrolyte_model.fit(\n",
    "    dataset.batch(1), epochs=4000, shuffle=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "electrolyte_model.save(\"TL_model1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3463a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history[\"loss\"], label=\"training\")\n",
    "#plt.plot(result.history[\"val_loss\"], label=\"validation\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8215e-706c-416f-927a-3802adb13745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
